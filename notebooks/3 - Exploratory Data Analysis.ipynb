{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
       "\n",
       "// needed to generate the Table of contents \n",
       "// taken from github.com/kmahelona/ipython_notebook_goodies\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
    "\n",
    "// needed to generate the Table of contents \n",
    "// taken from github.com/kmahelona/ipython_notebook_goodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#To work with Atom and Jupyter at the same time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from matplotlib import gridspec #gridspec allows me to make a subplot with different aspect ratio\n",
    "#from IPython.display import Image #used to display images saved to disk\n",
    "\n",
    "sns.set() #setting default Seaborn plot style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "from pandas_profiling.utils.cache import cache_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image #used to display images saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'train.csv' \n",
    "#try also 'data/test.csv' and 'data/RUL.csv' for similar results\n",
    "file_path = '../data/'+filename\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "df_RUL = pd.read_csv('../data/RUL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>cycle_time</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.36</td>\n",
       "      <td>1583.23</td>\n",
       "      <td>1396.84</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>8145.32</td>\n",
       "      <td>8.4246</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.11</td>\n",
       "      <td>23.3537</td>\n",
       "      <td>FD003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.50</td>\n",
       "      <td>1584.69</td>\n",
       "      <td>1396.89</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8152.85</td>\n",
       "      <td>8.4403</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4491</td>\n",
       "      <td>FD003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.18</td>\n",
       "      <td>1582.35</td>\n",
       "      <td>1405.61</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8150.17</td>\n",
       "      <td>8.3901</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.85</td>\n",
       "      <td>23.3669</td>\n",
       "      <td>FD003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.92</td>\n",
       "      <td>1585.61</td>\n",
       "      <td>1392.27</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8146.56</td>\n",
       "      <td>8.3878</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.96</td>\n",
       "      <td>23.2951</td>\n",
       "      <td>FD003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.68</td>\n",
       "      <td>1588.63</td>\n",
       "      <td>1397.65</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8147.80</td>\n",
       "      <td>8.3869</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.14</td>\n",
       "      <td>23.4583</td>\n",
       "      <td>FD003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  cycle_time  op_setting_1  op_setting_2  op_setting_3      s1  \\\n",
       "0            1           1       -0.0005        0.0004         100.0  518.67   \n",
       "1            1           2        0.0008       -0.0003         100.0  518.67   \n",
       "2            1           3       -0.0014       -0.0002         100.0  518.67   \n",
       "3            1           4       -0.0020        0.0001         100.0  518.67   \n",
       "4            1           5        0.0016        0.0000         100.0  518.67   \n",
       "\n",
       "       s2       s3       s4     s5  ...      s13      s14     s15   s16  s17  \\\n",
       "0  642.36  1583.23  1396.84  14.62  ...  2388.01  8145.32  8.4246  0.03  391   \n",
       "1  642.50  1584.69  1396.89  14.62  ...  2388.03  8152.85  8.4403  0.03  392   \n",
       "2  642.18  1582.35  1405.61  14.62  ...  2388.00  8150.17  8.3901  0.03  391   \n",
       "3  642.92  1585.61  1392.27  14.62  ...  2388.08  8146.56  8.3878  0.03  392   \n",
       "4  641.68  1588.63  1397.65  14.62  ...  2388.03  8147.80  8.3869  0.03  392   \n",
       "\n",
       "    s18    s19    s20      s21  dataset  \n",
       "0  2388  100.0  39.11  23.3537    FD003  \n",
       "1  2388  100.0  38.99  23.4491    FD003  \n",
       "2  2388  100.0  38.85  23.3669    FD003  \n",
       "3  2388  100.0  38.96  23.2951    FD003  \n",
       "4  2388  100.0  39.14  23.4583    FD003  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160359, 27)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "## Explore Data Relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience, identify the sensor and operational setting columns\n",
    "s_columns = [col for col in df.columns if col.startswith(\"s\")]\n",
    "op_setting_columns = [col for col in df.columns if col.startswith(\"op_setting\")]\n",
    "data_cols = op_setting_columns + s_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Pairplot of Operating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pair plot takes way too long there are too many variables\n",
    "# fig = plt.figure()\n",
    "# sns.pairplot(df[s_columns])\n",
    "# plt.savefig('../figures/pairplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic report with pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db7c394fcfb4afaa5c23ae338e7d455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=41.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ccecb31e0c4f4b87cf9c63a7a09fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176bd3fb83e845068fd42ad13636e0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render HTML', max=1.0, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131a7eaed9eb49298ab1a5aa2ff960cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Export report to file', max=1.0, style=ProgressStyle(descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'figures/data_profiling_report.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c2c102602831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprofile_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'style'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'full_width'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprofile_report\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"figures/data_profiling_report.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprofile_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Jet_clean/lib/python3.8/site-packages/pandas_profiling/profile_report.py\u001b[0m in \u001b[0;36mto_file\u001b[0;34m(self, output_file, silent)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Export report to file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_progress_bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         ) as pbar:\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0moutput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Jet_clean/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36mwrite_text\u001b[0;34m(self, data, encoding, errors)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             raise TypeError('data must be str, not %s' %\n\u001b[1;32m   1250\u001b[0m                             data.__class__.__name__)\n\u001b[0;32m-> 1251\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Jet_clean/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m         return io.open(self, mode, buffering, encoding, errors, newline,\n\u001b[0m\u001b[1;32m   1219\u001b[0m                        opener=self._opener)\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Jet_clean/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36m_opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0;31m# A stub for the opener argument to built-in open()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o777\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'figures/data_profiling_report.html'"
     ]
    }
   ],
   "source": [
    "profile_report = df.profile_report(html={'style': {'full_width': True}},progress_bar=True)\n",
    "profile_report.to_file(\"figures/data_profiling_report.html\")\n",
    "profile_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways :** Many sensor readings are fairly constant and probably will not be good predictors of the Remaning Usable Life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(df[op_setting_columns[0]],df[op_setting_columns[1]],df[op_setting_columns[2]])\n",
    "ax.set_xlabel(op_setting_columns[0])\n",
    "ax.set_ylabel(op_setting_columns[1])\n",
    "ax.set_zlabel(op_setting_columns[2])\n",
    "ax.set_title('Operating Conditions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rand_jitter(arr):\n",
    "    stdev = .03*(max(arr)-min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(rand_jitter(df[op_setting_columns[0]].values),rand_jitter(df[op_setting_columns[1]].values),rand_jitter(df[op_setting_columns[2]].values), s=1)\n",
    "ax.set_xlabel(op_setting_columns[0])\n",
    "ax.set_ylabel(op_setting_columns[1])\n",
    "ax.set_zlabel(op_setting_columns[2])\n",
    "ax.set_title('Operating Conditions (with added Jitter)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways :** We observe that the Operating condistions are clustered in 6 operating regimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histograms for each sensor column in df\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "hist = df[s_columns].hist(bins=50, figsize =(20,20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:** There are several sensor readings that have only a handful of values. Like s13, s16, s19. Sensors with constant values will unlikely be a good predictor of the engine degradation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification and creation of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Regime\n",
    "\n",
    "As we observed we have 6 operating regimes. Let's cluster the data and create a new variable *op_regime* which can replace the 3 op_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will fit the k-means algorithm with our k parameter set to 6, and plot the results.\n",
    "op_regimes = df[op_setting_columns].values\n",
    "kmeans6 = KMeans(n_clusters=6)\n",
    "y_kmeans6 = kmeans6.fit_predict(op_regimes)\n",
    "\n",
    "centers = kmeans6.cluster_centers_\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(op_regimes[:, 0], op_regimes[:, 1], op_regimes[:, 2], c=y_kmeans6, s=50, cmap='viridis', alpha=0.5)\n",
    "ax.scatter(centers[:, 0], centers[:, 1], centers[:, 2], marker='+', c='r', s=1000)\n",
    "\n",
    "ax.set_xlabel(op_setting_columns[0])\n",
    "ax.set_ylabel(op_setting_columns[1])\n",
    "ax.set_zlabel(op_setting_columns[2])\n",
    "ax.set_title('Operating Regimes')\n",
    "plt.savefig('../figures/Op_regime_clustering.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a op_regime column to the dataframe\n",
    "df['op_regime'] = y_kmeans6+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :** Do mulitple operating regime occur in each dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot distribution of operating regimes vs dataset\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.scatter(df['op_regime'],df['dataset'],s=20,c='k')\n",
    "plt.title('Operating Regimes in each *train* dataset')\n",
    "plt.xlabel('Operating Regime')\n",
    "plt.ylabel('Dataset')\n",
    "plt.savefig('../figures/Op_regime_vs_dataset.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use same model to add op_regime column to test data\n",
    "op_regimes_test = df_test[op_setting_columns].values\n",
    "df_test['op_regime'] = kmeans6.predict(op_regimes_test)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distribution of operating regimes vs dataset in the test data\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.scatter(df_test['op_regime'],df_test['dataset'],s=20,c='k')\n",
    "plt.title('Operating Regimes in each *test* dataset')\n",
    "plt.xlabel('Operating Regime')\n",
    "plt.ylabel('Dataset')\n",
    "plt.savefig('../figures/Op_regime_vs_dataset_test_data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway :** Dataset FD001 and FD003 feature data only for Operating regime #1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining Usable Life (RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a RUL column to the data. Translating the data so that the last cycle time for each time-series is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate maximum lifetime for each time-series\n",
    "lifetimes = df.groupby(['dataset', 'unit_number'])['cycle_time'].max()\n",
    "lifetimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(lifetimes['FD001'],\n",
    "             bins=20,\n",
    "             density=False,\n",
    "             histtype='step')\n",
    "\n",
    "_ = plt.title('Distribution of Lifetimes')\n",
    "_ = plt.xlabel('Lifetimes (cycles)')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "    # Number of data points: n\n",
    "    n = len(data)\n",
    "\n",
    "    # x-data for the ECDF: x\n",
    "    x = np.sort(data)\n",
    "\n",
    "    # y-data for the ECDF: y\n",
    "    y = np.arange(1, n+1) / n\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_life, y_life = ecdf(lifetimes['FD001'])\n",
    "percentiles =  np.array([5,50])\n",
    "percentiles_lifetimes = np.percentile(lifetimes['FD001'], percentiles)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax=fig.add_subplot(111)\n",
    "# Generate plot\n",
    "ax.plot(x_life, y_life,marker='.',linestyle='none')\n",
    "ax.plot(percentiles_lifetimes, percentiles/100, marker='D', color='red',\n",
    "         linestyle='none')\n",
    "# Label the axes\n",
    "# Label axes\n",
    "ax.annotate('5 percentile = {} cycles'.format(round(percentiles_lifetimes[0])), \n",
    "            xy=(percentiles_lifetimes[0], percentiles[0]/100), \n",
    "            xytext=(1.5*percentiles_lifetimes[0], 1.5*percentiles[0]/100),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "ax.annotate('50 percentile = {} cycles'.format(round(percentiles_lifetimes[1])), \n",
    "            xy=(percentiles_lifetimes[1], percentiles[1]/100), \n",
    "            xytext=(1.5*percentiles_lifetimes[1], 1.5*percentiles[1]/100),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "ax.set_title('Experimental cumulative Density Function of Lifetimes for dataset FD001 (ECDF)')\n",
    "ax.set_xlabel('Remainin Usable Life (cycles)')\n",
    "ax.set_ylabel('Lifetimes (cycles)')\n",
    "\n",
    "fig.savefig('../figures/lifetimes_FD001_ecdf.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a progress bar to this operation. We will use df.progress_apply instead of df.apply\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# calculate the Reamining Usable Life for each entry\n",
    "# WARNING!! : This can take a minute or two\n",
    "df['RUL'] = df.progress_apply( lambda row : row[\"cycle_time\"]-lifetimes.loc[row[\"dataset\"]].loc[row[\"unit_number\"]] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Test and RUL\n",
    "Let's do the same operation on the Test dataset, by taking into considertion the labels listed in RUL.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('data/test.csv')\n",
    "# df_RUL = pd.read_csv('data/RUL.csv')\n",
    "print(df_test.groupby(['unit_number', 'dataset']).sum().shape)\n",
    "print(df_RUL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RUL[df_RUL['unit_number']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_lifetimes = df_test.groupby(['dataset', 'unit_number'])['cycle_time'].max()\n",
    "rul = df_RUL.groupby(['dataset', 'unit_number'])['RUL'].max()\n",
    "df_test['RUL'] = df_test.progress_apply( lambda row : row[\"cycle_time\"]-partial_lifetimes.loc[row[\"dataset\"]].loc[row[\"unit_number\"]]-rul.loc[row[\"dataset\"]].loc[row[\"unit_number\"]] , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the sensor traces look like in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_list = df['dataset'].unique()\n",
    "\n",
    "for dataset_choice in tqdm(dataset_list, desc='Generating one image per dataset' ) :\n",
    "    # randomly select 10 units from dataset 1 to plot\n",
    "    all_units = df[df['dataset'] == dataset_choice]['unit_number'].unique()\n",
    "    units_to_plot = np.random.choice(all_units, size=10, replace=False)\n",
    "    # get the data for these units\n",
    "    plot_data = df[(df['dataset'] == dataset_choice) & (df['unit_number'].isin(units_to_plot))].copy()\n",
    "    # plot the sensor traces (overlaid)\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    fig, axes = plt.subplots(7, 3, figsize=(15, 10), sharex=True)\n",
    "    for index, ax in tqdm(enumerate(axes.ravel()), total=len(axes.ravel()), desc='Generating one sensor sub-plot', leave=False):\n",
    "        s_col = s_columns[index]\n",
    "        # use the same subset of data as above\n",
    "        for unit_id, group in tqdm(plot_data.groupby('unit_number'), desc='Overlaying sensor traces', leave=False):\n",
    "            # plot the raw sensor trace, using RUL on the time axis\n",
    "            (group\n",
    "                 .plot(x='RUL', y=s_col, alpha=0.45, ax=ax, color='gray', legend=False));\n",
    "            # overlay the 10-cycle rolling mean sensor trace for visual clarity\n",
    "            (group\n",
    "                 .rolling(window=10, on='RUL')\n",
    "                 .mean()\n",
    "                 .plot(x='RUL', y=s_col, alpha=.75, ax=ax, color='black', legend=False));\n",
    "        # label formatting\n",
    "        if index % 3 == 0:\n",
    "            ax.set_ylabel(\"Sensor Read\", size=10);\n",
    "        else:\n",
    "            ax.set_ylabel(\"\");\n",
    "        ax.set_title(s_col.title())\n",
    "        ax.set_xlabel(\"Remaining Usable Life (Cycles)\")\n",
    "        # add a vertical red line to signal common time of failure\n",
    "        ax.axvline(x=0, color='r', linewidth=1)\n",
    "        # extend the x-axis to compensate \n",
    "        ax.set_xlim([None, 10])\n",
    "    image_title = \"Dataset \"+dataset_choice+\" (Random Sample of 10 Units)\"\n",
    "    fig.suptitle(image_title, size=20, y=1.025)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    fig_path = 'figures/'+dataset_choice+\"_sensor_traces.png\"\n",
    "    fig.savefig(fig_path) \n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(filename='figures/FD001_sensor_traces.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/FD002_sensor_traces.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(filename='figures/FD003_sensor_traces.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(filename='figures/FD004_sensor_traces.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways :** Each dataset has distinctively different sensor profiles. In FD003 and FD004 are difficult to interpret, most sensors do not exhibit any obvious trend that might be a sign of degradation. In FD001 and FD002 we can weed out several sensors where the value is constant. In FD001 for example we could remove from the models sensors s1, s5, s10, s16, s18, s19 as their value does not change at all from cycle to cycle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## EDA Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with we will concentrate our efforts on modelling operating regime #1, thus we will only use dataset FD001 to begin with. Based on the findings we can expand and attempt to work with the other datasets as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op_regime2_FD001 = df[df['dataset'] == 'FD001'].copy()\n",
    "train_op_regime2_FD001.to_csv('data/train_op_regime2_FD001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = pd.read_csv('data/test.csv')\n",
    "test_op_regime2_FD001 = df_test[df_test['dataset'] == 'FD001'].copy()\n",
    "test_op_regime2_FD001.to_csv('data/test_op_regime2_FD001.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Jet_clean]",
   "language": "python",
   "name": "conda-env-Jet_clean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

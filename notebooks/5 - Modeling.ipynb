{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\\\"tocheading\\\">Table of Contents</h1>\n",
    "    <div id=\\\"toc\\\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
    "\n",
    "// needed to generate the Table of contents \n",
    "// taken from github.com/kmahelona/ipython_notebook_goodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Fit Models with Training Data Set\n",
    "\n",
    "## Review Model Outcomes â€” Iterate over additional models as needed.\n",
    "\n",
    "## Identify the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data and scaler model\n",
    "\n",
    "X_train_scaled = pd.read_csv(\"../data/X_train_scaled.csv\").to_numpy()\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\").to_numpy().ravel()\n",
    "X_test_scaled = pd.read_csv(\"../data/X_test_scaled.csv\").to_numpy()\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\").to_numpy().ravel()\n",
    "feature_list = pd.read_csv(\"../data/feature_list.csv\")\n",
    "feature_list = pd.Index(list(feature_list[\"0\"]))\n",
    "\n",
    "scaler = joblib.load(\"../data/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dict to collect model performance data\n",
    "models_comparison = {'Model': [],\n",
    "        'Explained Variance': [],\n",
    "        'Mean Absolute Error': [],\n",
    "        'Features Dropped': []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = .02  # step size in the mesh ???\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"Decision Tree\", \"Random Forest\", \"AdaBoost\",\n",
    "         \"Gradient Boosting\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()]\n",
    "\n",
    "all_params = { 'dictA': {'key_1': 'value_1'},\n",
    "                'dictB': {'key_2': 'value_2'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nearest Neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors':np.arange(1,101,2)}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn,param_grid,cv=5)\n",
    "start = timer()\n",
    "knn_cv.fit(X_train_scaled,y_train)\n",
    "end = timer()\n",
    "print(str(round(end - start,3)) + ' seconds elapsed.')\n",
    "print(\"Best Score:\" + str(knn_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(knn_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "param_grid = {'n_estimators':np.arange(50,200,50),\n",
    "              'criterion':['gini', 'entropy'],\n",
    "              'max_depth':np.arange(1,11,2),\n",
    "              }\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_cv= GridSearchCV(rfc,param_grid,cv=5)\n",
    "start = timer()\n",
    "rfc_cv.fit(X_train_scaled,y_train)\n",
    "end = timer()\n",
    "print(str(round(end - start,3)) + ' seconds elapsed.')\n",
    "print(\"Best Score:\" + str(rfc_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(rfc_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppor Vector Classifier - Linear\n",
    "param_grid = {'C' : np.arange(1,100,10),\n",
    "              'kernel': 'linear',\n",
    "              'gamma' : ['sacle','auto'],\n",
    "              }\n",
    "svc = SVC()\n",
    "svc_cv = GridSearchCV(svc,param_grid,cv=5)\n",
    "start = timer()\n",
    "svc_cv.fit(X_train_scaled,y_train)\n",
    "end = timer()\n",
    "print(str(round(end - start,3)) + ' seconds elapsed.')\n",
    "print(\"Best Score:\" + str(svc_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(svc_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bayes_opt import BayesianOptimization\n",
    "\n",
    "# name = names[0]\n",
    "# model = classifiers[0]\n",
    "\n",
    "# params_boundaries = {'n_neighbors':(3,11)}\n",
    "\n",
    "# def kNN_hyper_param(n_neighbors):\n",
    "#     clf = KNeighborsClassifier(n_neighbors)\n",
    "       \n",
    "#     return np.mean(cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring='accuracy'))\n",
    "\n",
    "# optimizer = BayesianOptimization(f=kNN_hyper_param, pbounds=params_boundaries, random_state = 33)\n",
    "# optimizer.maximize(n_iter=5, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Jet_clean]",
   "language": "python",
   "name": "conda-env-Jet_clean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
